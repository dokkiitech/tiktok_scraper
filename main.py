import asyncio
from playwright.async_api import async_playwright
import requests
import re
from datetime import datetime
import os

WEBHOOK_URL = 'https://script.google.com/macros/s/AKfycbytrfkniHTWKsXkNOD7hQNyYEcmOBMD7p89OmgXOsLkVD-LelEkrIEyoJJKv34HQxTw/exec'
SHARD_FILE = 'shard.txt'
KEYWORD_FILE = 'keyword.txt'

def load_keywords():
    try:
        with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip()]
            print(f"âœ… èª­ã¿è¾¼ã‚“ã ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {len(lines)}")
            return lines
    except Exception as e:
        print(f"âŒ keyword.txt èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def load_sent_ids():
    if not os.path.exists(SHARD_FILE):
        print("ğŸ†• shard.txt ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã®ã§æ–°è¦ä½œæˆã™ã‚‹ã‚ˆ")
        return set()
    with open(SHARD_FILE, 'r', encoding='utf-8') as f:
        sent = set(line.strip() for line in f if line.strip())
        print(f"ğŸ“‚ èª­ã¿è¾¼ã¿æ¸ˆã¿IDæ•°: {len(sent)}")
        return sent

def save_sent_id(user_url):
    with open(SHARD_FILE, 'a', encoding='utf-8') as f:
        f.write(user_url + '\n')
    print(f"ğŸ“ shard.txt ã«è¿½è¨˜: {user_url}")

async def scrape_keyword(keyword, sent_ids):
    query = keyword.replace(' ', '%')
    search_url = f"https://www.tiktok.com/search/video?q={query}"
    print(f"\nğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {keyword}")
    print(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: {search_url}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(viewport={"width": 600, "height": 800})
        page = await context.new_page()

        try:
            await page.goto(search_url)
            print("âœ… æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ")
            print("â³ 10ç§’å¾…æ©Ÿä¸­ï¼ˆTikTokã®åˆæœŸãƒ­ãƒ¼ãƒ‰çŒ¶äºˆï¼‰...")
            await asyncio.sleep(15)

            locator = page.locator("a[href*='/video/']")
            count = await locator.count()
            print(f"ğŸï¸ æ¤œå‡ºã•ã‚ŒãŸå‹•ç”»æ•°: {count}")
            if count == 0:
                print("âš ï¸ å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—")
                await browser.close()
                return

            await locator.first.click()
            print("âœ… æœ€åˆã®å‹•ç”»ã‚’ã‚¯ãƒªãƒƒã‚¯")
            await asyncio.sleep(3)

        except Exception as e:
            print(f"âŒ å‹•ç”»ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}")
            await browser.close()
            return

        last_url = ""
        while True:
            try:
                current_url = page.url
                print(f"â¡ï¸ ç¾åœ¨ã®å‹•ç”»URL: {current_url}")

                if current_url != last_url and '/video/' in current_url and '@' in current_url:
                    last_url = current_url
                    match = re.search(r'tiktok\.com/@([^/]+)', current_url)
                    if match:
                        user_id = match.group(1)
                        user_url = f"https://www.tiktok.com/@{user_id}"
                        if user_url in sent_ids:
                            print(f"âš ï¸ é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {user_url}")
                        else:
                            payload = {
                                'userId': user_id,
                                'source': f'keyword:{keyword}',
                                'timestamp': datetime.now().isoformat()
                            }
                            print(f"ğŸ“¡ GASã¸é€ä¿¡: {payload}")
                            res = requests.post(WEBHOOK_URL, json=payload)
                            print(f"ğŸ“¬ GASã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {res.status_code} / ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {res.text.strip()}")

                            if res.status_code == 200 and res.text.strip() != 'duplicate':
                                save_sent_id(user_url)
                                sent_ids.add(user_url)
                            else:
                                print("âš ï¸ GASå´ã§ã‚¹ã‚­ãƒƒãƒ— or duplicate")

                await page.keyboard.press("ArrowDown")
                print("â¬‡ï¸ â†“ã‚­ãƒ¼é€ä¿¡ â†’ æ¬¡ã®å‹•ç”»ã¸")
                await asyncio.sleep(2)

            except Exception as e:
                print(f"âŒ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­æ–­: {e}")
                break

        await browser.close()

async def main():
    keywords = load_keywords()
    if not keywords:
        print("ğŸ›‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç©ºã§ã™ã€‚çµ‚äº†ã—ã¾ã™")
        return

    sent_ids = load_sent_ids()
    for keyword in keywords:
        await scrape_keyword(keyword, sent_ids)

asyncio.run(main())
